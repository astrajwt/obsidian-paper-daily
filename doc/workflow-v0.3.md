# Paper Daily â€” Daily Pipeline Workflow v0.3

> æ–‡ä»¶è·¯å¾„ï¼š`src/pipeline/dailyPipeline.ts`
> è§¦å‘æ–¹å¼ï¼šæ‰‹åŠ¨å‘½ä»¤ / æ¯æ—¥å®šæ—¶ï¼ˆé»˜è®¤ 08:30ï¼‰/ backfill

---

## æ€»è§ˆ

```
Step 1   â†’  Fetch arXiv
Step 1b  â†’  Fetch HuggingFace + Merge
Step 2   â†’  Dedupï¼ˆå…¨å±€å»é‡ï¼‰
Step 2b  â†’  Interest-only filterï¼ˆå¯é€‰ï¼‰
Step 3   â†’  å…³é”®è¯æ’åˆ†ï¼ˆhfScore + interestScoreï¼‰
Step 3b  â†’  LLM å¿«é€Ÿæ‰“åˆ†ï¼ˆå¯é€‰ï¼Œä¸Šé™ 60 ç¯‡ï¼‰
Step 3d  â†’  PDF ä¸‹è½½ï¼ˆå¯é€‰ï¼‰
Step 3f  â†’  Deep Read ç²¾è¯»ï¼ˆå¯é€‰ï¼Œä¸Šé™ topN ç¯‡ï¼‰
Step 4   â†’  LLM ç”Ÿæˆæ—¥æŠ¥æ‘˜è¦
Step 5   â†’  å†™å…¥ Markdownï¼ˆinbox/YYYY-MM-DD.mdï¼‰
Step 6   â†’  å†™å…¥ Snapshot JSONï¼ˆpapers/YYYY-MM-DD.jsonï¼‰
Step 7   â†’  æ›´æ–°å»é‡ç¼“å­˜ï¼ˆseen_ids.jsonï¼‰
Step 8   â†’  æ›´æ–° state.json
```

å¤±è´¥ç­–ç•¥ï¼šFetch å¤±è´¥æˆ– LLM å¤±è´¥å‡ä¸é˜»æ–­å†™å…¥ï¼Œæœ€ç»ˆ Markdown é‡Œä¼šåŒ…å«é”™è¯¯åŸå› ã€‚

---

## Step 1 â€” Fetch arXiv

**åšä»€ä¹ˆ**
è°ƒç”¨ arXiv Atom APIï¼ŒæŒ‰åˆ†ç±»æŠ“å–æŒ‡å®šæ—¶é—´çª—å£å†…çš„è®ºæ–‡ã€‚

**å‚æ•°ï¼ˆå‡æ¥è‡ª settingsï¼‰**

| å‚æ•° | å€¼ / æ¥æº |
|---|---|
| categories | ç”¨æˆ·é…ç½®ï¼Œå¦‚ `cs.AI,cs.LG,cs.CL` |
| keywords | å›ºå®šä¸ºç©ºæ•°ç»„ï¼ˆä¸åšå…³é”®è¯ API è¿‡æ»¤ï¼Œé æœ¬åœ°æ‰“åˆ†ï¼‰ |
| maxResults | ç¡¬ç¼–ç  200 |
| sortBy | ç¡¬ç¼–ç  `submittedDate` |
| timeWindow | `[now - timeWindowHours, now]`ï¼Œ`timeWindowHours` ç”¨æˆ·å¯é…ï¼ˆé»˜è®¤ 72hï¼‰ |

**è¾“å‡º**
`Paper[]`ï¼Œæ¯æ¡åŒ…å«ï¼š`id`ï¼ˆå¦‚ `arxiv:2501.12345v2`ï¼‰ã€`title`ã€`authors`ã€`abstract`ã€`categories`ã€`published`ã€`updated`ã€`links.html`ã€`links.pdf`ã€`source: "arxiv"`

**å¤±è´¥è¡Œä¸º**ï¼šfetchError è®°å½•ï¼Œç»§ç»­æ‰§è¡Œåç»­æ­¥éª¤ã€‚

---

## Step 1b â€” Fetch HuggingFace + Merge

**åšä»€ä¹ˆ**
ä» `huggingface.co/papers` æŠ“å–å½“æ—¥ç²¾é€‰è®ºæ–‡åˆ—è¡¨ï¼ˆHTML scrapingï¼‰ã€‚ä»Šæ—¥æ— æ•°æ®æ—¶ï¼ˆå‘¨æœ«/èŠ‚å‡æ—¥ï¼‰å‘å‰å›æº¯æœ€å¤š `lookbackDays` å¤©ã€‚

**å‚æ•°**

| å‚æ•° | å€¼ / æ¥æº |
|---|---|
| lookbackDays | ç”¨æˆ·å¯é…ï¼ˆé»˜è®¤ 3ï¼‰ |
| è§¦å‘æ¡ä»¶ | `hfSource.enabled !== false`ï¼ˆé»˜è®¤å¼€å¯ï¼‰ |

**Merge é€»è¾‘**

1. **arXiv âˆ© HF**ï¼šå¦‚æœ HF ç²¾é€‰é‡Œæœ‰è®ºæ–‡ä¸ arXiv ç»“æœ id åŒ¹é…ï¼ˆå»ç‰ˆæœ¬å·æ¯”å¯¹ï¼‰ï¼Œåˆ™æŠŠ `hfUpvotes` å’Œ `links.hf` å†™å…¥å¯¹åº” arXiv è®ºæ–‡å¯¹è±¡ã€‚
2. **HF-only**ï¼šHF ç²¾é€‰ä¸­ä¸åœ¨ arXiv ç»“æœé‡Œçš„è®ºæ–‡ï¼Œç›´æ¥è¿½åŠ è¿› `papers[]` å‚ä¸åç»­æ‰“åˆ†ã€‚

**è¾“å‡º**
åˆå¹¶åçš„ `papers[]`ï¼ŒarXiv è®ºæ–‡å¯èƒ½æ–°å¢ `hfUpvotes` / `links.hf`ï¼›HF-only è®ºæ–‡ `source: "hf"`ã€‚

åŒæ—¶ä¿ç•™å®Œæ•´ `hfDailyPapers[]`ï¼ˆåŸå§‹ HF åˆ—è¡¨ï¼Œåç»­é€ LLM ä½œä¸ºå‚è€ƒï¼‰ã€‚

---

## Step 2 â€” Dedupï¼ˆå…¨å±€å»é‡ï¼‰

**åšä»€ä¹ˆ**
ä» `seen_ids.json`ï¼ˆDedupStoreï¼‰è¿‡æ»¤æ‰å·²åœ¨ä¹‹å‰æŸå¤©æ—¥æŠ¥ä¸­å‡ºç°è¿‡çš„è®ºæ–‡ idã€‚

**å‚æ•°**

| å‚æ•° | å€¼ |
|---|---|
| å¼€å…³ | `settings.dedup`ï¼ˆç”¨æˆ·å¯é…ï¼Œé»˜è®¤ trueï¼‰ |
| è·³è¿‡æ¡ä»¶ | `options.skipDedup === true`ï¼ˆbackfill æ¨¡å¼å¯ä¼ å…¥ï¼‰ |

**è¾“å‡º**
è¿‡æ»¤åçš„ `papers[]`ï¼Œå·²è§è¿‡çš„ id è¢«ç§»é™¤ã€‚

---

## Step 2b â€” Interest-only Filterï¼ˆå¯é€‰ï¼‰

**åšä»€ä¹ˆ**
ä»…åœ¨ `fetchMode === "interest_only"` æ—¶æ‰§è¡Œã€‚é¢„å…ˆè®¡ç®—æ¯ç¯‡è®ºæ–‡çš„å…´è¶£å…³é”®è¯å‘½ä¸­ï¼Œè¿‡æ»¤æ‰é›¶å‘½ä¸­çš„è®ºæ–‡ã€‚

**å‚æ•°**

| å‚æ•° | å€¼ |
|---|---|
| è§¦å‘æ¡ä»¶ | `settings.fetchMode === "interest_only"` ä¸” `interestKeywords.length > 0` |

**å‘½ä¸­è§„åˆ™**
é€ä¸ªå…³é”®è¯åœ¨ `title + abstract` å…¨æ–‡ä¸­åšä¸åŒºåˆ†å¤§å°å†™çš„å­ä¸²åŒ¹é…ï¼Œå†™å…¥ `paper.interestHits: string[]`ã€‚

**è¾“å‡º**
è¿‡æ»¤åçš„ `papers[]`ï¼Œæ¯ç¯‡è‡³å°‘å‘½ä¸­ä¸€ä¸ªå…´è¶£å…³é”®è¯ã€‚

---

## Step 3 â€” å…³é”®è¯æ’åˆ†

**åšä»€ä¹ˆ**
å¯¹ `papers[]` åšåˆæ­¥æ’åºï¼Œç¡®å®š LLM æ‰“åˆ†ä¼˜å…ˆå¤„ç†å“ªäº›è®ºæ–‡ã€‚

**æ‰“åˆ†å…¬å¼**
```
rankScore = hfScore + interestScore

hfScore      = hfUpvotes Ã— 1.0  ï¼ˆHF ç‚¹èµæ•°ï¼‰
interestScore = Î£( keyword.weight )  å¯¹æ‰€æœ‰å‘½ä¸­çš„å…³é”®è¯æ±‚æƒé‡ä¹‹å’Œ
```

**è¾“å‡º**
`rankedPapers[]`ï¼ŒæŒ‰ `rankScore` é™åºæ’åˆ—ï¼Œ`paper.interestHits` å·²å¡«å……ã€‚

---

## Step 3b â€” LLM å¿«é€Ÿæ‰“åˆ†

**åšä»€ä¹ˆ**
ç”¨ LLM å¯¹æ’åé å‰çš„è®ºæ–‡åšè´¨é‡è¯„åˆ†ï¼ˆ1â€“10ï¼‰ï¼Œå¹¶ç”Ÿæˆä¸€å¥è¯æ‘˜è¦ã€‚æ‰“åˆ†ç»“æœè¦†ç›–ä¸Šä¸€æ­¥çš„å…³é”®è¯æ’åˆ†ï¼Œé‡æ–°æ’åºã€‚

**è§¦å‘æ¡ä»¶**ï¼š`rankedPapers.length > 0 && settings.llm.apiKey` å·²é…ç½®

**è¾“å…¥æˆªå–**ï¼šå–å‰ min(æ€»æ•°, 60) ç¯‡ï¼Œæ¯ç¯‡æä¾›ï¼š
- `id`
- `title`
- `abstract`ï¼ˆæˆªå–å‰ 250 å­—ç¬¦ï¼‰
- `interestHits`
- `hfUpvotes`ï¼ˆå¦‚æœ‰ï¼‰

**Promptï¼ˆç¡¬ç¼–ç ï¼Œä¸å¯é…ç½®ï¼‰**

```
Score each paper 1â€“10 for quality and relevance to the user's interests.

User's interest keywords (higher weight = more important): {kwStr}

Scoring criteria:
- Alignment with interest keywords and their weights
- Technical novelty and depth
- Practical engineering value
- Quality of evaluation / experiments

Return ONLY a valid JSON array, no explanation, no markdown fence:
[{"id":"arxiv:...","score":8,"reason":"one short phrase","summary":"1â€“2 sentence plain-language summary"},...]

Papers:
{papersForScoring JSON}
```

**å‚æ•°**
- temperature: 0.1
- maxTokens: min(scoringCap Ã— 150 + 256, 8192)

**è¾“å‡º**
è§£æ JSON æ•°ç»„ï¼Œå›å¡« `paper.llmScore`ã€`paper.llmScoreReason`ã€`paper.llmSummary`ï¼›
æŒ‰ `llmScore` é™åºé‡æ–°æ’åˆ— `rankedPapers[]`ã€‚

**å¤±è´¥è¡Œä¸º**ï¼šé fatalï¼Œä¿ç•™å…³é”®è¯æ’åé¡ºåºç»§ç»­ã€‚

---

## Step 3d â€” PDF ä¸‹è½½ï¼ˆå¯é€‰ï¼‰

**åšä»€ä¹ˆ**
å¯¹ `rankedPapers[]` ä¸­æ‰€æœ‰æœ‰ `links.pdf` çš„è®ºæ–‡é€ä¸€ä¸‹è½½ PDFï¼Œä¿å­˜åˆ° Vaultã€‚

**è§¦å‘æ¡ä»¶**ï¼š`settings.paperDownload.savePdf === true`

**å­˜å‚¨è·¯å¾„**
```
{rootFolder}/papers/pdf/{YYYY-MM-DD}/{arxivId}.pdf
```

**è¡Œä¸º**
- å·²å­˜åœ¨åˆ™è·³è¿‡ï¼ˆä¸é‡å¤ä¸‹è½½ï¼‰
- ä¸‹è½½æˆåŠŸåå†™å…¥ `paper.links.localPdf = vaultå†…ç›¸å¯¹è·¯å¾„`
- æ¯ç¯‡ä¹‹é—´ sleep 1200msï¼ˆé¿å…é¢‘ç‡é™åˆ¶ï¼‰

**è¾“å‡º**ï¼š`paper.links.localPdf` è¢«å¡«å……ï¼ˆä¾›åç»­ Markdown æ„å»ºå’Œ LLM prompt ä½¿ç”¨ï¼‰

---

## Step 3f â€” Deep Read ç²¾è¯»ï¼ˆå¯é€‰ï¼‰

**åšä»€ä¹ˆ**
å¯¹æ’åæœ€é«˜çš„ topN ç¯‡è®ºæ–‡ï¼Œå„è‡ªå‘èµ·ä¸€æ¬¡ç‹¬ç«‹ LLM è°ƒç”¨ï¼Œè®©æ¨¡å‹æ·±åº¦åˆ†æè¯¥è®ºæ–‡ã€‚æ¨¡å‹ä¼šæ”¶åˆ° `arxiv.org/html/{id}` URLï¼Œå¦‚æœæ¨¡å‹å…·å¤‡ URL è®¿é—®èƒ½åŠ›ï¼ˆå¦‚ Claudeï¼‰å¯ç›´æ¥è¯»å…¨æ–‡ã€‚

**è§¦å‘æ¡ä»¶**ï¼š`settings.deepRead.enabled === true`

**å‚æ•°**

| å‚æ•° | æ¥æº |
|---|---|
| topN | `settings.deepRead.topN`ï¼ˆé»˜è®¤ 5ï¼‰ |
| maxTokens | `settings.deepRead.deepReadMaxTokens`ï¼ˆé»˜è®¤ 1024ï¼‰ |
| prompt æ¨¡æ¿ | `settings.deepRead.deepReadPromptTemplate` æˆ– DEFAULT_DEEP_READ_PROMPT |
| temperature | 0.2 |

**æ¯ç¯‡ Prompt è¾“å…¥ï¼ˆDEFAULT_DEEP_READ_PROMPT æ¨¡æ¿ï¼‰**

```
Title: {{title}}
Authors: {{authors}}
Interest keyword hits: {{interest_hits}}
Abstract: {{abstract}}
Full paper HTML (read directly if you can access URLs): {{fulltext}}   â† arxiv.org/html/{id}
```

**è¦æ±‚è¾“å‡ºæ ¼å¼**
- æ ¸å¿ƒè´¡çŒ® / Core Contributionï¼ˆ2â€“3 å¥ï¼‰
- æ–¹æ³•äº®ç‚¹ / Method Highlightsï¼ˆ2â€“4 bulletï¼‰
- å®éªŒä¸ç»“æœ / Experiments & Resultsï¼ˆ2â€“3 å¥ï¼‰
- å·¥ç¨‹å¯ç¤º / Engineering Takeawayï¼ˆ1â€“2 å¥ï¼‰
- å±€é™æ€§ / Limitationsï¼ˆ1â€“2 å¥ï¼‰
- ç›®æ ‡ 400 å­—ä»¥å†…

**è¾“å‡º**
`paper.deepReadAnalysis` å­—ç¬¦ä¸²ï¼›
æ‰€æœ‰åˆ†ææ‹¼åˆä¸º `fulltextSection`ï¼ˆMarkdown æ ¼å¼ï¼‰ï¼Œä¼ å…¥ Step 4 çš„ `{{fulltext_section}}`ã€‚

**å¤±è´¥è¡Œä¸º**ï¼šå•ç¯‡å¤±è´¥ä¸å½±å“å…¶ä»–ç¯‡ï¼Œnon-fatalã€‚

---

## Step 4 â€” LLM æ—¥æŠ¥ç”Ÿæˆ

**åšä»€ä¹ˆ**
ç”¨ç”¨æˆ·é€‰å®šçš„ Prompt æ¨¡æ¿ï¼Œå°†å…¨éƒ¨ä¸Šä¸‹æ–‡ç»„è£…æˆä¸€ä¸ª promptï¼Œè°ƒç”¨ LLM ç”Ÿæˆæœ€ç»ˆæ—¥æŠ¥æ­£æ–‡ã€‚

**è§¦å‘æ¡ä»¶**ï¼š`rankedPapers.length > 0 && settings.llm.apiKey` å·²é…ç½®

**è¾“å…¥æ•°æ®**

| å ä½ç¬¦ | å†…å®¹ |
|---|---|
| `{{date}}` | å½“æ—¥æ—¥æœŸ YYYY-MM-DD |
| `{{papers_json}}` | å‰ min(æ€»æ•°, 10) ç¯‡è®ºæ–‡çš„ JSONï¼Œæ¯ç¯‡å« id/title/abstract(500å­—)/categories/interestHits/hfUpvotes/links ç­‰ |
| `{{hf_papers_json}}` | HF æ¯æ—¥ç²¾é€‰åŸå§‹åˆ—è¡¨ï¼ˆå‰ 15 æ¡ï¼‰ï¼Œå« title/hfUpvotes/streakDays |
| `{{fulltext_section}}` | Deep Read åˆ†æç»“æœï¼ˆMarkdownï¼‰ï¼Œæœªå¼€å¯æ—¶ä¸ºç©ºå­—ç¬¦ä¸² |
| `{{local_pdfs}}` | å·²ä¸‹è½½ PDF çš„è®ºæ–‡åˆ—è¡¨ï¼ˆMarkdown é“¾æ¥ï¼‰ï¼Œæœªä¸‹è½½æ—¶ä¸ºç©ºå­—ç¬¦ä¸² |
| `{{interest_keywords}}` | ç”¨æˆ·å…´è¶£å…³é”®è¯åŠæƒé‡ï¼Œå¦‚ `rlhf(weight:5), agent(weight:5), ...` |
| `{{language}}` | `Chinese (ä¸­æ–‡)` æˆ– `English` |

**æ¨¡å‹å‚æ•°**
- provider / model / temperature / maxTokensï¼šå…¨éƒ¨æ¥è‡ª `settings.llm`

**å½“å‰å†…ç½® Prompt æ¨¡æ¿ï¼ˆå·¥ç¨‹ç²¾è¯»ï¼‰è¦æ±‚çš„è¾“å‡ºæ ¼å¼**

```
### ä»Šæ—¥è¦ç‚¹ / Key Takeaways
3â€“5 bullet points

### ç²¾é€‰è®ºæ–‡ / Curated Papers
æ¯ç¯‡ï¼šâ­è¯„çº§ / å…³é”®è¯ / æ ¸å¿ƒè´¡çŒ® / æ–¹æ³•æ ¸å¿ƒ / å®éªŒä¸¥è°¨æ€§ / å·¥ç¨‹å¯ç¤º / å±€é™æ€§ / å»ºè®® / é“¾æ¥

### HF ç¤¾åŒºä¿¡å· / HF Community Signal
æœªè¢«ç²¾é€‰è¦†ç›–çš„ HF çƒ­é—¨è®ºæ–‡ï¼Œä¸€è¡Œä¸€æ¡

### ä»Šæ—¥æ‰¹æ¬¡è´¨é‡ & ç»“è¯­ / Batch Quality & Closing
2â€“3 å¥æ€»ç»“
```

**è¾“å‡º**ï¼š`llmDigest` å­—ç¬¦ä¸²ï¼Œå†™å…¥ Markdownã€‚

**å¤±è´¥è¡Œä¸º**ï¼šllmError è®°å½•ï¼ŒMarkdown é‡Œ AI æ‘˜è¦åŒºæ˜¾ç¤ºé”™è¯¯åŸå› ã€‚

---

## Step 5 â€” å†™å…¥ Markdown

**åšä»€ä¹ˆ**
å°†æ‰€æœ‰å†…å®¹æ‹¼è£…ä¸º Markdown æ–‡ä»¶ï¼Œå†™å…¥ Vaultã€‚

**è¾“å‡ºè·¯å¾„**
```
{rootFolder}/inbox/YYYY-MM-DD.md
```

**æ–‡ä»¶ç»“æ„**

```markdown
---
type: paper-daily
date: YYYY-MM-DD
sources: [arxiv, huggingface]
categories: [cs.AI, cs.LG, cs.CL]
interestKeywords: [rlhf(5), agent(5), ...]
---

# Paper Daily â€” YYYY-MM-DD

## ä»Šæ—¥è¦ç‚¹ï¼ˆAI æ€»ç»“ï¼‰ | by {model} è€å¸ˆ ğŸ¤–
{llmDigest}

## æœ¬åœ° PDF / Local PDFs (N ç¯‡)        â† ä»… savePdf=true ä¸”æœ‰ä¸‹è½½æ—¶æ˜¾ç¤º
- [Title A](PaperDaily/papers/pdf/2026-03-01/xxx.pdf)
- ...

## All Papers
| # | Title | Links | Score | Summary | Hits |
|---|-------|-------|-------|---------|------|
| 1 | [Title](arxiv_url) | [arXiv](...) [ğŸ¤— HF](...) [PDF](...) [Local PDF](...) | â­8/10 | summary | kw1, kw2 |
...
```

---

## Step 6 â€” å†™å…¥ Snapshot JSON

**è¾“å‡ºè·¯å¾„**
```
{rootFolder}/papers/YYYY-MM-DD.json
```

**å†…å®¹**ï¼šå®Œæ•´ `Paper[]`ï¼Œå«æ‰€æœ‰è®¡ç®—å­—æ®µï¼ˆllmScoreã€llmSummaryã€interestHitsã€deepReadAnalysis ç­‰ï¼‰ï¼Œä¾›å‘¨æŠ¥/æœˆæŠ¥è¯»å–ã€‚

---

## Step 7 â€” æ›´æ–°å»é‡ç¼“å­˜

å°†æœ¬æ¬¡æ‰€æœ‰ `rankedPapers` çš„ id å†™å…¥ `seen_ids.json`ï¼ˆè®°å½• `paperId â†’ firstSeenDate`ï¼‰ã€‚

**æ¡ä»¶**ï¼š`dedupEnabled === true`ï¼ˆsettings.dedup ä¸”é skipDedup æ¨¡å¼ï¼‰

---

## Step 8 â€” æ›´æ–° state.json

å†™å…¥ `lastDailyRun: ISOæ—¶é—´æˆ³`ï¼Œä¾› scheduler åˆ¤æ–­ä»Šå¤©æ˜¯å¦å·²è¿è¡Œè¿‡ã€‚

**æ¡ä»¶**ï¼šé backfill æ¨¡å¼ï¼ˆ`options.targetDate` æœªä¼ å…¥ï¼‰

---

## Token ç”¨é‡ç»Ÿè®¡

æ¯æ­¥ LLM è°ƒç”¨çš„ input/output tokens ç´¯è®¡ï¼Œæœ€ç»ˆåœ¨è¿›åº¦æ¶ˆæ¯é‡Œæ˜¾ç¤ºï¼š
```
âœ… å®Œæˆï¼42 ç¯‡è®ºæ–‡ | tokens: 12,450â†’3,210
```

---

## é™„ï¼šå„æ­¥éª¤æ•°æ®æµç¤ºæ„

```
arXiv API â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                                 â–¼
HF scraper â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’  Merge â”€â”€â”€â”€â”€â”€â†’  papers[] (â‰¤200+HF)
                                                 â”‚
                                       Step 2: Dedup filter
                                                 â”‚
                                   Step 2b: Interest-only filter (å¯é€‰)
                                                 â”‚
                                       Step 3: rankPapers()
                                          hfScore + interestScore
                                                 â”‚
                                   Step 3b: LLM scoring (å‰60ç¯‡)
                                          llmScore è¦†ç›–æ’å
                                                 â”‚
                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                          â”‚                      â”‚
                   Step 3d: PDFä¸‹è½½        Step 3f: Deep Read
                   paper.links.localPdf    paper.deepReadAnalysis
                          â”‚                      â”‚
                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                 â”‚
                                       Step 4: LLM digest
                                         top 10ç¯‡ + HF 15æ¡
                                         + deepRead section
                                         + local PDFs list
                                         + interest_keywords
                                                 â”‚
                                Step 5: Markdown â†’ inbox/YYYY-MM-DD.md
                                Step 6: JSON    â†’ papers/YYYY-MM-DD.json
                                Step 7: Dedup   â†’ cache/seen_ids.json
                                Step 8: State   â†’ cache/state.json
```

---

## å¯é…ç½®é¡¹é€ŸæŸ¥

| è®¾ç½® | é»˜è®¤å€¼ | å½±å“æ­¥éª¤ |
|---|---|---|
| categories | cs.AI,cs.LG,cs.CL | Step 1 |
| timeWindowHours | 72 | Step 1 |
| fetchMode | all | Step 2b |
| dedup | true | Step 2, 7 |
| hfSource.lookbackDays | 3 | Step 1b |
| paperDownload.savePdf | true | Step 3d, Step 5 |
| deepRead.enabled | false | Step 3f |
| deepRead.topN | 5 | Step 3f |
| deepRead.deepReadMaxTokens | 1024 | Step 3f |
| interestKeywords | 10æ¡é»˜è®¤ | Step 2b, 3, 3b, 4 |
| llm.model / temperature / maxTokens | gpt-4o-mini / 0.3 / 4096 | Step 3b, 3f, 4 |
| activePromptId | builtin_engineering | Step 4 |
